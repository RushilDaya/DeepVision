{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_n_images(data, start, end, loc):\n",
    "    images_list = list(zip(*data[mode][start:end]))[0]\n",
    "    labels_list = list(zip(*data[mode][start:end]))[1]\n",
    "    labels_list = np.array(labels_list).nonzero()[-1] # Convert dummy encoding to categorical (one number per category)\n",
    "    images = [cv2.imread(\"{}/{}.jpg\".format(loc, image)) for image in images_list]\n",
    "    return np.array(images), labels_list\n",
    "\n",
    "def generate_img_from_folder(data_dir, mode, batch_size, autoencoder=True):\n",
    "    \"\"\"must be jpg\"\"\"\n",
    "    loc = \"{}/{}\".format(data_dir,mode)    \n",
    "    while True:\n",
    "        with open('{}/labels.pickle'.format(data_dir), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        modes = list(data.keys())\n",
    "        del modes[-1]\n",
    "        \n",
    "        assert mode in modes, \"'{}' not a valid mode (must be one of {})\".format(mode, str(modes))\n",
    "        assert glob.glob(loc), \"Check directory.\"\n",
    "        assert glob.glob(\"{}/*.jpg\".format(loc)), \"Check file extension (should be 'jpg').\"\n",
    "        \n",
    "        \n",
    "        for idx in range(0,len(data[mode]), batch_size):\n",
    "            start = idx\n",
    "            end = idx+batch_size\n",
    "            \n",
    "            images, labels = read_n_images(data, start, end, loc)\n",
    "            if autoencoder:\n",
    "                yield (images, images) # would be label if not autoencoder\n",
    "            else:\n",
    "                yield (images, labels) # For classification (can't classify two images at once)\n",
    "                \n",
    "                \n",
    "def get_input_shape(data_dir, mode):\n",
    "    \"\"\"must be jpg\"\"\"\n",
    "    loc = \"{}/{}\".format(data_dir,mode)\n",
    "    with open('{}/labels.pickle'.format(data_dir), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    idx = 0 # Arbitrarily chosen\n",
    "    img = cv2.imread(\"{}/{}.jpg\".format(loc, data[mode][idx][0]))\n",
    "    return img.shape\n",
    "\n",
    "def get_num_examples(data_dir, mode):\n",
    "    with open('{}/labels.pickle'.format(data_dir), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return len(data[mode])\n",
    "\n",
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
    "           label = 'Val Error')\n",
    "    #plt.ylim([20,40])\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "MODE = 'training'\n",
    "in_shape = get_input_shape(DATA_DIR, MODE)\n",
    "\n",
    "\n",
    "\n",
    "input_img = Input(shape=in_shape)  # adapt this if using `channels_first` image data format\n",
    "#input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_140 (Conv2D)          (None, 200, 200, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 100, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_141 (Conv2D)          (None, 100, 100, 8)       1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 50, 50, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_142 (Conv2D)          (None, 50, 50, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_143 (Conv2D)          (None, 25, 25, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_60 (UpSampling (None, 50, 50, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_144 (Conv2D)          (None, 50, 50, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_61 (UpSampling (None, 100, 100, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_145 (Conv2D)          (None, 100, 100, 16)      1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_62 (UpSampling (None, 200, 200, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_146 (Conv2D)          (None, 200, 200, 3)       435       \n",
      "=================================================================\n",
      "Total params: 4,963\n",
      "Trainable params: 4,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 167s 1s/step - loss: -17657.9311 - acc: 0.0029\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = get_num_examples(DATA_DIR, MODE)\n",
    "BATCH_SIZE = 10\n",
    "STEPS_PER_EPOCH = ceil(NUM_SAMPLES/BATCH_SIZE)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = autoencoder.fit_generator(generate_img_from_folder(DATA_DIR, MODE, BATCH_SIZE), shuffle=True, steps_per_epoch=STEPS_PER_EPOCH, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17724.606836</td>\n",
       "      <td>0.002878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss       acc\n",
       "0 -17724.606836  0.002878"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Decoding images\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
